{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(model, data_path):\n",
    "    df = pd.read_csv(data_path + \"_train.tsv\", sep='\\t')\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "    max_len = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        text = df.cleaned_text[i]\n",
    "\n",
    "        s = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"do_not_pad\",\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",  # to get a torch.Tensor\n",
    "            truncation=True,\n",
    "        )\n",
    "\n",
    "        max_len.append(len(s['input_ids'][0]))\n",
    "\n",
    "    print(f\"len for {model} --- {data_path.split('/')[-1].split('_')[0]} => max = {max(max_len)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len for distilbert-base-cased --- tamil => max = 187\n",
      "len for ai4bharat/indic-bert --- tamil => max = 276\n"
     ]
    }
   ],
   "source": [
    "get_max_len('distilbert-base-cased', './data/tamil_offensive')\n",
    "# get_max_len('distilbert-base-cased', './data/malayalam_hasoc')\n",
    "\n",
    "get_max_len('ai4bharat/indic-bert', './data/tamil_offensive')\n",
    "# get_max_len('ai4bharat/indic-bert', './data/malayalam_hasoc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-cased')\n",
    "df = pd.read_csv(\"./data/tamil_codemix_offensive_train.tsv\", sep='\\t')\n",
    "\n",
    "def convert(text):\n",
    "    return tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=512,\n",
    "        return_token_type_ids=False,\n",
    "        padding=\"max_length\",\n",
    "        return_attention_mask=True,\n",
    "        return_tensors=\"pt\",  # to get a torch.Tensor\n",
    "        truncation=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, model_name, hidden_states=256, dropout=0.5, n_classes=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.lin0 = nn.Linear(self.bert.config.hidden_size, hidden_states)\n",
    "        self.lin1 = nn.Linear(hidden_states, n_classes)\n",
    "        self.reLU = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        output = output.last_hidden_state\n",
    "        output = torch.sum(output, dim=1) / torch.sum(attention_mask, axis=1).view(output.shape[0], 1)\n",
    "        y = self.lin0(output)\n",
    "        y = self.reLU(y)\n",
    "        y = self.dropout(y)\n",
    "        return self.lin1(y)\n",
    "\n",
    "\n",
    "model = TransformerClassifier('distilbert-base-cased', 768, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = convert(df.cleaned_text[0])\n",
    "data2 = convert(df.cleaned_text[1])\n",
    "\n",
    "in_ = torch.cat([data1['input_ids'], data2['input_ids']])\n",
    "out_ = torch.cat([data1['attention_mask'], data2['attention_mask']])\n",
    "\n",
    "outputs = model(\n",
    "    input_ids=in_,\n",
    "    attention_mask=out_,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5818, -0.7787],\n",
       "        [ 0.4718,  0.1129]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
